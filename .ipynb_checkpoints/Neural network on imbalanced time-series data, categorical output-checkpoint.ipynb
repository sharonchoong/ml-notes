{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target at time n will be sin(x1<sub>n-1</sub>) + cos(x2<sub>n-1</sub>) + tan(x1<sub>n-1</sub> + x2<sub>n-1</sub>) where x1 and x2 are the features. Both x1 and x2 are randomly generated numbers between -1 and 1. The LAG response will be a binary variable if positive/negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>response</th>\n",
       "      <th>LAG_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.892401</td>\n",
       "      <td>0.163061</td>\n",
       "      <td>0.839180</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.609522</td>\n",
       "      <td>0.950474</td>\n",
       "      <td>-0.685575</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.169819</td>\n",
       "      <td>-0.536533</td>\n",
       "      <td>0.363630</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.460706</td>\n",
       "      <td>-0.448193</td>\n",
       "      <td>-0.162723</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.045847</td>\n",
       "      <td>-0.821941</td>\n",
       "      <td>1.358325</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>-0.006947</td>\n",
       "      <td>0.544640</td>\n",
       "      <td>1.000797</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0.374841</td>\n",
       "      <td>0.858580</td>\n",
       "      <td>1.444666</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>0.580474</td>\n",
       "      <td>0.698402</td>\n",
       "      <td>3.870374</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>-0.844387</td>\n",
       "      <td>-0.439188</td>\n",
       "      <td>4.642028</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>-0.865002</td>\n",
       "      <td>-0.029820</td>\n",
       "      <td>-3.227836</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>736 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2  response LAG_response\n",
       "1   -0.892401  0.163061  0.839180         True\n",
       "2   -0.609522  0.950474 -0.685575        False\n",
       "3   -0.169819 -0.536533  0.363630         True\n",
       "4    0.460706 -0.448193 -0.162723        False\n",
       "5   -0.045847 -0.821941  1.358325         True\n",
       "..        ...       ...       ...          ...\n",
       "732 -0.006947  0.544640  1.000797        False\n",
       "733  0.374841  0.858580  1.444666        False\n",
       "734  0.580474  0.698402  3.870374        False\n",
       "735 -0.844387 -0.439188  4.642028         True\n",
       "736 -0.865002 -0.029820 -3.227836         True\n",
       "\n",
       "[736 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/data.csv')\n",
    "df['LAG_response'] = df['response'].shift(-1)  ## 1 time step lag\n",
    "df = df.dropna()\n",
    "df['LAG_response'] = pd.Categorical(df['LAG_response'] < 0)\n",
    "#df = df.drop(['response'], axis=1)\n",
    "dates = df.pop('date')\n",
    "\n",
    "for col in df.columns: \n",
    "    df = df.rename({col: col.replace(' ', '_').replace('&', '')}, axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop('LAG_response')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.360000e+02</td>\n",
       "      <td>7.360000e+02</td>\n",
       "      <td>736.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.111837e-18</td>\n",
       "      <td>1.077980e-16</td>\n",
       "      <td>0.037905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000680e+00</td>\n",
       "      <td>1.000680e+00</td>\n",
       "      <td>0.481164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.763215e+00</td>\n",
       "      <td>-1.722513e+00</td>\n",
       "      <td>-5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.649978e-01</td>\n",
       "      <td>-8.514864e-01</td>\n",
       "      <td>0.048075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.847800e-02</td>\n",
       "      <td>-1.763602e-02</td>\n",
       "      <td>0.071143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.815953e-01</td>\n",
       "      <td>8.212859e-01</td>\n",
       "      <td>0.095204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.706569e+00</td>\n",
       "      <td>1.774070e+00</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x1            x2    response\n",
       "count  7.360000e+02  7.360000e+02  736.000000\n",
       "mean   2.111837e-18  1.077980e-16    0.037905\n",
       "std    1.000680e+00  1.000680e+00    0.481164\n",
       "min   -1.763215e+00 -1.722513e+00   -5.000000\n",
       "25%   -8.649978e-01 -8.514864e-01    0.048075\n",
       "50%    4.847800e-02 -1.763602e-02    0.071143\n",
       "75%    8.815953e-01  8.212859e-01    0.095204\n",
       "max    1.706569e+00  1.774070e+00    5.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### normalize features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "y = df.pop('LAG_response')\n",
    "\n",
    "def normalize_column(df):\n",
    "    scaler = StandardScaler()\n",
    "    df = pd.DataFrame(scaler.fit_transform(df.values), columns = df.columns, index= df.index)\n",
    "    df = pd.DataFrame(np.clip(df, -5, 5), columns = df.columns, index= df.index)\n",
    "    return df\n",
    "        \n",
    "df = normalize_column(df)\n",
    "df['LAG_response'] = y.values\n",
    "\n",
    "total_ds = df_to_dataset(df, shuffle=False, batch_size=len(df))\n",
    "total_df = df.copy()\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x211dd0c8908>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['LAG_response'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train and test dataset splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### oversample categorical y to rebalance\n",
    "def oversample(df):\n",
    "    data_negativeResponse = df[df['LAG_response']]\n",
    "    data_positiveResponse = df[df['LAG_response'] != True]\n",
    "    choices = np.random.choice(len(data_negativeResponse), len(data_positiveResponse))\n",
    "    sample_negativeResponse = data_negativeResponse.iloc[choices]\n",
    "    df = pd.concat([sample_negativeResponse,data_positiveResponse]) \n",
    "    df['LAG_response'].value_counts().plot(kind='bar')\n",
    "    return df\n",
    "\n",
    "train = oversample(train)\n",
    "val = oversample(val)\n",
    "test = oversample(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(df)\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "headers = [\n",
    "            \"x1\", \n",
    "            \"x2\"\n",
    "          ]\n",
    "# numeric cols\n",
    "for header in headers:\n",
    "    feature_columns.append(feature_column.numeric_column(header))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(bias, threshold=0.5):\n",
    "    if bias is not None:\n",
    "        bias = keras.initializers.Constant(bias)\n",
    "    model = tf.keras.Sequential()\n",
    "    # Add feature layer\n",
    "    model.add(layers.DenseFeatures(feature_columns))\n",
    "    # Adds a densely-connected layer with 64 units to the model:\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    #model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    # Add the output layer:\n",
    "    model.add(layers.Dense(1, activation='sigmoid', bias_initializer= bias))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[keras.metrics.BinaryAccuracy(threshold=threshold), keras.metrics.Precision(thresholds=threshold), keras.metrics.Recall(thresholds=threshold), \n",
    "                           keras.metrics.AUC(name=\"auc\")])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    513\n",
      "True     223\n",
      "Name: LAG_response, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "##output_bias \n",
    "print(df['LAG_response'].value_counts())\n",
    "#initial_bias = np.log([lacking_samples/overflowing_samples])\n",
    "\n",
    "#plot loss\n",
    "import matplotlib.pyplot as plt\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "def plot_loss(model_fit, label, n, other_metric=None):\n",
    "    plt.semilogy(model_fit.epoch, model_fit.history['loss'], color=colors[n], label=\"Train \"+label)\n",
    "    plt.semilogy(model_fit.epoch, model_fit.history['val_loss'], color=colors[n], label='Val '+label, linestyle='--')\n",
    "    if other_metric:\n",
    "        plt.plot(model_fit.epoch, model_fit.history[other_metric], color=colors[n], label=other_metric, linestyle='dashdot')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "#model = make_model(None)\n",
    "#plot_loss(model.fit(train_ds, epochs=50, verbose=0,validation_data=val_ds), \"Default bias\", 0)\n",
    "\n",
    "#model = make_model(initial_bias)\n",
    "#plot_loss(model.fit(train_ds, epochs=50, verbose=0,validation_data=val_ds), \"Custom bias\", 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 - 5s - loss: 1.0404 - binary_accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3103 - val_loss: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "1/1 - 0s - loss: 1.0122 - binary_accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4167 - val_loss: 0.9838 - val_binary_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5908\n",
      "Epoch 3/500\n",
      "1/1 - 0s - loss: 0.9859 - binary_accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5458 - val_loss: 0.9584 - val_binary_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6292\n",
      "Epoch 4/500\n",
      "1/1 - 0s - loss: 0.9603 - binary_accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5878 - val_loss: 0.9344 - val_binary_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6611\n",
      "Epoch 5/500\n",
      "1/1 - 0s - loss: 0.9360 - binary_accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6200 - val_loss: 0.9103 - val_binary_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6758\n",
      "Epoch 6/500\n",
      "1/1 - 0s - loss: 0.9116 - binary_accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6379 - val_loss: 0.8854 - val_binary_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6948\n",
      "Epoch 7/500\n",
      "1/1 - 0s - loss: 0.8866 - binary_accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6500 - val_loss: 0.8591 - val_binary_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7025\n",
      "Epoch 8/500\n",
      "1/1 - 0s - loss: 0.8602 - binary_accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6629 - val_loss: 0.8315 - val_binary_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7272\n",
      "Epoch 9/500\n",
      "1/1 - 0s - loss: 0.8325 - binary_accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6848 - val_loss: 0.8029 - val_binary_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7464\n",
      "Epoch 10/500\n",
      "1/1 - 0s - loss: 0.8038 - binary_accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7086 - val_loss: 0.7734 - val_binary_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7792\n",
      "Epoch 11/500\n",
      "1/1 - 0s - loss: 0.7740 - binary_accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7390 - val_loss: 0.7429 - val_binary_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8107\n",
      "Epoch 12/500\n",
      "1/1 - 0s - loss: 0.7431 - binary_accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7689 - val_loss: 0.7111 - val_binary_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8325\n",
      "Epoch 13/500\n",
      "1/1 - 0s - loss: 0.7110 - binary_accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8004 - val_loss: 0.6782 - val_binary_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8575\n",
      "Epoch 14/500\n",
      "1/1 - 0s - loss: 0.6780 - binary_accuracy: 0.5018 - precision: 1.0000 - recall: 0.0035 - auc: 0.8273 - val_loss: 0.6445 - val_binary_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8734\n",
      "Epoch 15/500\n",
      "1/1 - 0s - loss: 0.6445 - binary_accuracy: 0.5140 - precision: 1.0000 - recall: 0.0281 - auc: 0.8493 - val_loss: 0.6099 - val_binary_accuracy: 0.5203 - val_precision: 0.8571 - val_recall: 0.0488 - val_auc: 0.8852\n",
      "Epoch 16/500\n",
      "1/1 - 0s - loss: 0.6107 - binary_accuracy: 0.5246 - precision: 0.9375 - recall: 0.0526 - auc: 0.8690 - val_loss: 0.5749 - val_binary_accuracy: 0.5732 - val_precision: 0.9500 - val_recall: 0.1545 - val_auc: 0.8977\n",
      "Epoch 17/500\n",
      "1/1 - 0s - loss: 0.5772 - binary_accuracy: 0.5491 - precision: 0.8043 - recall: 0.1298 - auc: 0.8828 - val_loss: 0.5404 - val_binary_accuracy: 0.5935 - val_precision: 0.8710 - val_recall: 0.2195 - val_auc: 0.9039\n",
      "Epoch 18/500\n",
      "1/1 - 0s - loss: 0.5449 - binary_accuracy: 0.5737 - precision: 0.7763 - recall: 0.2070 - auc: 0.8897 - val_loss: 0.5074 - val_binary_accuracy: 0.6870 - val_precision: 0.8833 - val_recall: 0.4309 - val_auc: 0.9110\n",
      "Epoch 19/500\n",
      "1/1 - 0s - loss: 0.5150 - binary_accuracy: 0.6667 - precision: 0.8519 - recall: 0.4035 - auc: 0.8931 - val_loss: 0.4769 - val_binary_accuracy: 0.7114 - val_precision: 0.8939 - val_recall: 0.4797 - val_auc: 0.9161\n",
      "Epoch 20/500\n",
      "1/1 - 0s - loss: 0.4885 - binary_accuracy: 0.7421 - precision: 0.8632 - recall: 0.5754 - auc: 0.8957 - val_loss: 0.4497 - val_binary_accuracy: 0.7642 - val_precision: 0.9114 - val_recall: 0.5854 - val_auc: 0.9188\n",
      "Epoch 21/500\n",
      "1/1 - 0s - loss: 0.4662 - binary_accuracy: 0.8000 - precision: 0.8670 - recall: 0.7088 - auc: 0.8977 - val_loss: 0.4261 - val_binary_accuracy: 0.8415 - val_precision: 0.9200 - val_recall: 0.7480 - val_auc: 0.9197\n",
      "Epoch 22/500\n",
      "1/1 - 0s - loss: 0.4482 - binary_accuracy: 0.8351 - precision: 0.8604 - recall: 0.8000 - auc: 0.8993 - val_loss: 0.4058 - val_binary_accuracy: 0.8415 - val_precision: 0.9038 - val_recall: 0.7642 - val_auc: 0.9206\n",
      "Epoch 23/500\n",
      "1/1 - 0s - loss: 0.4341 - binary_accuracy: 0.8789 - precision: 0.8673 - recall: 0.8947 - auc: 0.9019 - val_loss: 0.3882 - val_binary_accuracy: 0.8943 - val_precision: 0.8943 - val_recall: 0.8943 - val_auc: 0.9264\n",
      "Epoch 24/500\n",
      "1/1 - 0s - loss: 0.4229 - binary_accuracy: 0.8877 - precision: 0.8623 - recall: 0.9228 - auc: 0.9049 - val_loss: 0.3727 - val_binary_accuracy: 0.8943 - val_precision: 0.8943 - val_recall: 0.8943 - val_auc: 0.9295\n",
      "Epoch 25/500\n",
      "1/1 - 0s - loss: 0.4138 - binary_accuracy: 0.8895 - precision: 0.8558 - recall: 0.9368 - auc: 0.9080 - val_loss: 0.3587 - val_binary_accuracy: 0.9024 - val_precision: 0.9091 - val_recall: 0.8943 - val_auc: 0.9319\n",
      "Epoch 26/500\n",
      "1/1 - 0s - loss: 0.4058 - binary_accuracy: 0.8860 - precision: 0.8503 - recall: 0.9368 - auc: 0.9112 - val_loss: 0.3456 - val_binary_accuracy: 0.9065 - val_precision: 0.9167 - val_recall: 0.8943 - val_auc: 0.9327\n",
      "Epoch 27/500\n",
      "1/1 - 0s - loss: 0.3978 - binary_accuracy: 0.8860 - precision: 0.8503 - recall: 0.9368 - auc: 0.9130 - val_loss: 0.3333 - val_binary_accuracy: 0.9146 - val_precision: 0.9322 - val_recall: 0.8943 - val_auc: 0.9340\n",
      "Epoch 28/500\n",
      "1/1 - 0s - loss: 0.3895 - binary_accuracy: 0.8842 - precision: 0.8476 - recall: 0.9368 - auc: 0.9157 - val_loss: 0.3222 - val_binary_accuracy: 0.9268 - val_precision: 0.9565 - val_recall: 0.8943 - val_auc: 0.9349\n",
      "Epoch 29/500\n",
      "1/1 - 0s - loss: 0.3810 - binary_accuracy: 0.8947 - precision: 0.8641 - recall: 0.9368 - auc: 0.9171 - val_loss: 0.3124 - val_binary_accuracy: 0.9268 - val_precision: 0.9565 - val_recall: 0.8943 - val_auc: 0.9374\n",
      "Epoch 30/500\n",
      "1/1 - 0s - loss: 0.3728 - binary_accuracy: 0.8965 - precision: 0.8669 - recall: 0.9368 - auc: 0.9183 - val_loss: 0.3044 - val_binary_accuracy: 0.9228 - val_precision: 0.9643 - val_recall: 0.8780 - val_auc: 0.9386\n",
      "Epoch 31/500\n",
      "1/1 - 0s - loss: 0.3655 - binary_accuracy: 0.9000 - precision: 0.8775 - recall: 0.9298 - auc: 0.9191 - val_loss: 0.2986 - val_binary_accuracy: 0.9228 - val_precision: 0.9815 - val_recall: 0.8618 - val_auc: 0.9416\n",
      "Epoch 32/500\n",
      "1/1 - 0s - loss: 0.3597 - binary_accuracy: 0.9035 - precision: 0.8912 - recall: 0.9193 - auc: 0.9187 - val_loss: 0.2952 - val_binary_accuracy: 0.9187 - val_precision: 0.9813 - val_recall: 0.8537 - val_auc: 0.9414\n",
      "Epoch 33/500\n",
      "1/1 - 0s - loss: 0.3559 - binary_accuracy: 0.9000 - precision: 0.9043 - recall: 0.8947 - auc: 0.9202 - val_loss: 0.2934 - val_binary_accuracy: 0.9106 - val_precision: 0.9903 - val_recall: 0.8293 - val_auc: 0.9440\n",
      "Epoch 34/500\n",
      "1/1 - 0s - loss: 0.3539 - binary_accuracy: 0.9000 - precision: 0.9130 - recall: 0.8842 - auc: 0.9208 - val_loss: 0.2921 - val_binary_accuracy: 0.9106 - val_precision: 0.9903 - val_recall: 0.8293 - val_auc: 0.9520\n",
      "Epoch 35/500\n",
      "1/1 - 0s - loss: 0.3530 - binary_accuracy: 0.8965 - precision: 0.9248 - recall: 0.8632 - auc: 0.9259 - val_loss: 0.2901 - val_binary_accuracy: 0.9065 - val_precision: 0.9902 - val_recall: 0.8211 - val_auc: 0.9568\n",
      "Epoch 36/500\n",
      "1/1 - 0s - loss: 0.3523 - binary_accuracy: 0.8912 - precision: 0.9305 - recall: 0.8456 - auc: 0.9284 - val_loss: 0.2868 - val_binary_accuracy: 0.9065 - val_precision: 0.9902 - val_recall: 0.8211 - val_auc: 0.9593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/500\n",
      "1/1 - 0s - loss: 0.3512 - binary_accuracy: 0.8842 - precision: 0.9294 - recall: 0.8316 - auc: 0.9328 - val_loss: 0.2818 - val_binary_accuracy: 0.9065 - val_precision: 0.9902 - val_recall: 0.8211 - val_auc: 0.9661\n",
      "Epoch 38/500\n",
      "1/1 - 0s - loss: 0.3492 - binary_accuracy: 0.8842 - precision: 0.9294 - recall: 0.8316 - auc: 0.9361 - val_loss: 0.2758 - val_binary_accuracy: 0.9065 - val_precision: 0.9902 - val_recall: 0.8211 - val_auc: 0.9706\n",
      "Epoch 39/500\n",
      "1/1 - 0s - loss: 0.3467 - binary_accuracy: 0.8825 - precision: 0.9258 - recall: 0.8316 - auc: 0.9382 - val_loss: 0.2693 - val_binary_accuracy: 0.9065 - val_precision: 0.9902 - val_recall: 0.8211 - val_auc: 0.9735\n",
      "Epoch 40/500\n",
      "1/1 - 0s - loss: 0.3439 - binary_accuracy: 0.8842 - precision: 0.9195 - recall: 0.8421 - auc: 0.9396 - val_loss: 0.2627 - val_binary_accuracy: 0.9065 - val_precision: 0.9902 - val_recall: 0.8211 - val_auc: 0.9750\n",
      "Epoch 41/500\n",
      "1/1 - 0s - loss: 0.3413 - binary_accuracy: 0.8825 - precision: 0.9160 - recall: 0.8421 - auc: 0.9411 - val_loss: 0.2565 - val_binary_accuracy: 0.9065 - val_precision: 0.9902 - val_recall: 0.8211 - val_auc: 0.9761\n",
      "Epoch 42/500\n",
      "1/1 - 0s - loss: 0.3391 - binary_accuracy: 0.8895 - precision: 0.9142 - recall: 0.8596 - auc: 0.9421 - val_loss: 0.2511 - val_binary_accuracy: 0.9065 - val_precision: 0.9808 - val_recall: 0.8293 - val_auc: 0.9772\n",
      "Epoch 43/500\n",
      "1/1 - 0s - loss: 0.3372 - binary_accuracy: 0.8877 - precision: 0.9048 - recall: 0.8667 - auc: 0.9430 - val_loss: 0.2466 - val_binary_accuracy: 0.9146 - val_precision: 0.9811 - val_recall: 0.8455 - val_auc: 0.9775\n",
      "Epoch 44/500\n",
      "1/1 - 0s - loss: 0.3355 - binary_accuracy: 0.8912 - precision: 0.8940 - recall: 0.8877 - auc: 0.9440 - val_loss: 0.2429 - val_binary_accuracy: 0.9146 - val_precision: 0.9811 - val_recall: 0.8455 - val_auc: 0.9791\n",
      "Epoch 45/500\n",
      "1/1 - 0s - loss: 0.3336 - binary_accuracy: 0.8912 - precision: 0.8940 - recall: 0.8877 - auc: 0.9443 - val_loss: 0.2399 - val_binary_accuracy: 0.9187 - val_precision: 0.9813 - val_recall: 0.8537 - val_auc: 0.9794\n",
      "Epoch 46/500\n",
      "1/1 - 0s - loss: 0.3313 - binary_accuracy: 0.8947 - precision: 0.8920 - recall: 0.8982 - auc: 0.9444 - val_loss: 0.2376 - val_binary_accuracy: 0.9187 - val_precision: 0.9813 - val_recall: 0.8537 - val_auc: 0.9795\n",
      "Epoch 47/500\n",
      "1/1 - 0s - loss: 0.3285 - binary_accuracy: 0.8982 - precision: 0.8927 - recall: 0.9053 - auc: 0.9450 - val_loss: 0.2361 - val_binary_accuracy: 0.9187 - val_precision: 0.9813 - val_recall: 0.8537 - val_auc: 0.9796\n",
      "Epoch 48/500\n",
      "1/1 - 0s - loss: 0.3253 - binary_accuracy: 0.8982 - precision: 0.8927 - recall: 0.9053 - auc: 0.9452 - val_loss: 0.2354 - val_binary_accuracy: 0.9187 - val_precision: 0.9813 - val_recall: 0.8537 - val_auc: 0.9796\n",
      "Epoch 49/500\n",
      "1/1 - 0s - loss: 0.3220 - binary_accuracy: 0.9018 - precision: 0.9046 - recall: 0.8982 - auc: 0.9452 - val_loss: 0.2356 - val_binary_accuracy: 0.9146 - val_precision: 0.9904 - val_recall: 0.8374 - val_auc: 0.9802\n",
      "Epoch 50/500\n",
      "1/1 - 0s - loss: 0.3189 - binary_accuracy: 0.9018 - precision: 0.9046 - recall: 0.8982 - auc: 0.9451 - val_loss: 0.2362 - val_binary_accuracy: 0.9146 - val_precision: 0.9904 - val_recall: 0.8374 - val_auc: 0.9804\n",
      "Epoch 51/500\n",
      "1/1 - 0s - loss: 0.3160 - binary_accuracy: 0.9053 - precision: 0.9110 - recall: 0.8982 - auc: 0.9452 - val_loss: 0.2370 - val_binary_accuracy: 0.9106 - val_precision: 0.9903 - val_recall: 0.8293 - val_auc: 0.9811\n",
      "Epoch 52/500\n",
      "1/1 - 0s - loss: 0.3135 - binary_accuracy: 0.9035 - precision: 0.9137 - recall: 0.8912 - auc: 0.9454 - val_loss: 0.2373 - val_binary_accuracy: 0.9106 - val_precision: 0.9903 - val_recall: 0.8293 - val_auc: 0.9812\n",
      "Epoch 53/500\n",
      "1/1 - 0s - loss: 0.3110 - binary_accuracy: 0.8947 - precision: 0.9121 - recall: 0.8737 - auc: 0.9453 - val_loss: 0.2364 - val_binary_accuracy: 0.9106 - val_precision: 0.9903 - val_recall: 0.8293 - val_auc: 0.9819\n",
      "Epoch 54/500\n",
      "1/1 - 0s - loss: 0.3084 - binary_accuracy: 0.8947 - precision: 0.9121 - recall: 0.8737 - auc: 0.9460 - val_loss: 0.2343 - val_binary_accuracy: 0.9106 - val_precision: 0.9903 - val_recall: 0.8293 - val_auc: 0.9822\n",
      "Epoch 55/500\n",
      "1/1 - 0s - loss: 0.3054 - binary_accuracy: 0.8965 - precision: 0.9154 - recall: 0.8737 - auc: 0.9467 - val_loss: 0.2311 - val_binary_accuracy: 0.9106 - val_precision: 0.9903 - val_recall: 0.8293 - val_auc: 0.9827\n",
      "Epoch 56/500\n",
      "1/1 - 0s - loss: 0.3024 - binary_accuracy: 0.9053 - precision: 0.9170 - recall: 0.8912 - auc: 0.9474 - val_loss: 0.2272 - val_binary_accuracy: 0.9146 - val_precision: 0.9904 - val_recall: 0.8374 - val_auc: 0.9831\n",
      "Epoch 57/500\n",
      "1/1 - 0s - loss: 0.2993 - binary_accuracy: 0.9053 - precision: 0.9110 - recall: 0.8982 - auc: 0.9481 - val_loss: 0.2230 - val_binary_accuracy: 0.9146 - val_precision: 0.9904 - val_recall: 0.8374 - val_auc: 0.9836\n",
      "Epoch 58/500\n",
      "1/1 - 0s - loss: 0.2963 - binary_accuracy: 0.9088 - precision: 0.9117 - recall: 0.9053 - auc: 0.9489 - val_loss: 0.2189 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9847\n",
      "Epoch 59/500\n",
      "1/1 - 0s - loss: 0.2933 - binary_accuracy: 0.9140 - precision: 0.9126 - recall: 0.9158 - auc: 0.9499 - val_loss: 0.2152 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9847\n",
      "Epoch 60/500\n",
      "1/1 - 0s - loss: 0.2903 - binary_accuracy: 0.9175 - precision: 0.9132 - recall: 0.9228 - auc: 0.9508 - val_loss: 0.2122 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9847\n",
      "Epoch 61/500\n",
      "1/1 - 0s - loss: 0.2872 - binary_accuracy: 0.9175 - precision: 0.9132 - recall: 0.9228 - auc: 0.9514 - val_loss: 0.2096 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9849\n",
      "Epoch 62/500\n",
      "1/1 - 0s - loss: 0.2840 - binary_accuracy: 0.9175 - precision: 0.9132 - recall: 0.9228 - auc: 0.9518 - val_loss: 0.2074 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9857\n",
      "Epoch 63/500\n",
      "1/1 - 0s - loss: 0.2807 - binary_accuracy: 0.9211 - precision: 0.9138 - recall: 0.9298 - auc: 0.9520 - val_loss: 0.2055 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9859\n",
      "Epoch 64/500\n",
      "1/1 - 0s - loss: 0.2774 - binary_accuracy: 0.9175 - precision: 0.9161 - recall: 0.9193 - auc: 0.9523 - val_loss: 0.2036 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9861\n",
      "Epoch 65/500\n",
      "1/1 - 0s - loss: 0.2742 - binary_accuracy: 0.9158 - precision: 0.9187 - recall: 0.9123 - auc: 0.9525 - val_loss: 0.2011 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9863\n",
      "Epoch 66/500\n",
      "1/1 - 0s - loss: 0.2709 - binary_accuracy: 0.9193 - precision: 0.9253 - recall: 0.9123 - auc: 0.9530 - val_loss: 0.1980 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9868\n",
      "Epoch 67/500\n",
      "1/1 - 0s - loss: 0.2675 - binary_accuracy: 0.9211 - precision: 0.9286 - recall: 0.9123 - auc: 0.9535 - val_loss: 0.1941 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9881\n",
      "Epoch 68/500\n",
      "1/1 - 0s - loss: 0.2642 - binary_accuracy: 0.9193 - precision: 0.9283 - recall: 0.9088 - auc: 0.9539 - val_loss: 0.1897 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9884\n",
      "Epoch 69/500\n",
      "1/1 - 0s - loss: 0.2608 - binary_accuracy: 0.9193 - precision: 0.9283 - recall: 0.9088 - auc: 0.9542 - val_loss: 0.1853 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9888\n",
      "Epoch 70/500\n",
      "1/1 - 0s - loss: 0.2573 - binary_accuracy: 0.9211 - precision: 0.9286 - recall: 0.9123 - auc: 0.9548 - val_loss: 0.1813 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9890\n",
      "Epoch 71/500\n",
      "1/1 - 0s - loss: 0.2539 - binary_accuracy: 0.9263 - precision: 0.9263 - recall: 0.9263 - auc: 0.9554 - val_loss: 0.1780 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9891\n",
      "Epoch 72/500\n",
      "1/1 - 0s - loss: 0.2504 - binary_accuracy: 0.9263 - precision: 0.9263 - recall: 0.9263 - auc: 0.9556 - val_loss: 0.1752 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9892\n",
      "Epoch 73/500\n",
      "1/1 - 0s - loss: 0.2470 - binary_accuracy: 0.9316 - precision: 0.9271 - recall: 0.9368 - auc: 0.9558 - val_loss: 0.1727 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/500\n",
      "1/1 - 0s - loss: 0.2437 - binary_accuracy: 0.9316 - precision: 0.9271 - recall: 0.9368 - auc: 0.9560 - val_loss: 0.1702 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9894\n",
      "Epoch 75/500\n",
      "1/1 - 0s - loss: 0.2402 - binary_accuracy: 0.9316 - precision: 0.9271 - recall: 0.9368 - auc: 0.9562 - val_loss: 0.1674 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9898\n",
      "Epoch 76/500\n",
      "1/1 - 0s - loss: 0.2367 - binary_accuracy: 0.9316 - precision: 0.9271 - recall: 0.9368 - auc: 0.9570 - val_loss: 0.1642 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9898\n",
      "Epoch 77/500\n",
      "1/1 - 0s - loss: 0.2332 - binary_accuracy: 0.9368 - precision: 0.9308 - recall: 0.9439 - auc: 0.9576 - val_loss: 0.1610 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9900\n",
      "Epoch 78/500\n",
      "1/1 - 0s - loss: 0.2296 - binary_accuracy: 0.9456 - precision: 0.9320 - recall: 0.9614 - auc: 0.9583 - val_loss: 0.1579 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9899\n",
      "Epoch 79/500\n",
      "1/1 - 0s - loss: 0.2261 - binary_accuracy: 0.9474 - precision: 0.9322 - recall: 0.9649 - auc: 0.9592 - val_loss: 0.1553 - val_binary_accuracy: 0.9228 - val_precision: 0.9906 - val_recall: 0.8537 - val_auc: 0.9902\n",
      "Epoch 80/500\n",
      "1/1 - 0s - loss: 0.2228 - binary_accuracy: 0.9491 - precision: 0.9354 - recall: 0.9649 - auc: 0.9598 - val_loss: 0.1531 - val_binary_accuracy: 0.9309 - val_precision: 0.9907 - val_recall: 0.8699 - val_auc: 0.9907\n",
      "Epoch 81/500\n",
      "1/1 - 0s - loss: 0.2195 - binary_accuracy: 0.9596 - precision: 0.9426 - recall: 0.9789 - auc: 0.9602 - val_loss: 0.1509 - val_binary_accuracy: 0.9309 - val_precision: 0.9907 - val_recall: 0.8699 - val_auc: 0.9914\n",
      "Epoch 82/500\n",
      "1/1 - 0s - loss: 0.2162 - binary_accuracy: 0.9596 - precision: 0.9396 - recall: 0.9825 - auc: 0.9607 - val_loss: 0.1482 - val_binary_accuracy: 0.9309 - val_precision: 0.9907 - val_recall: 0.8699 - val_auc: 0.9914\n",
      "Epoch 83/500\n",
      "1/1 - 0s - loss: 0.2130 - binary_accuracy: 0.9614 - precision: 0.9398 - recall: 0.9860 - auc: 0.9612 - val_loss: 0.1452 - val_binary_accuracy: 0.9309 - val_precision: 0.9907 - val_recall: 0.8699 - val_auc: 0.9911\n",
      "Epoch 84/500\n",
      "1/1 - 0s - loss: 0.2097 - binary_accuracy: 0.9614 - precision: 0.9398 - recall: 0.9860 - auc: 0.9616 - val_loss: 0.1426 - val_binary_accuracy: 0.9309 - val_precision: 0.9907 - val_recall: 0.8699 - val_auc: 0.9910\n",
      "Epoch 85/500\n",
      "1/1 - 0s - loss: 0.2065 - binary_accuracy: 0.9632 - precision: 0.9430 - recall: 0.9860 - auc: 0.9621 - val_loss: 0.1408 - val_binary_accuracy: 0.9309 - val_precision: 0.9907 - val_recall: 0.8699 - val_auc: 0.9911\n",
      "Epoch 86/500\n",
      "1/1 - 0s - loss: 0.2034 - binary_accuracy: 0.9632 - precision: 0.9430 - recall: 0.9860 - auc: 0.9624 - val_loss: 0.1396 - val_binary_accuracy: 0.9309 - val_precision: 0.9907 - val_recall: 0.8699 - val_auc: 0.9912\n",
      "Epoch 87/500\n",
      "1/1 - 0s - loss: 0.2004 - binary_accuracy: 0.9632 - precision: 0.9430 - recall: 0.9860 - auc: 0.9629 - val_loss: 0.1384 - val_binary_accuracy: 0.9309 - val_precision: 0.9907 - val_recall: 0.8699 - val_auc: 0.9912\n",
      "Epoch 88/500\n",
      "1/1 - 0s - loss: 0.1973 - binary_accuracy: 0.9614 - precision: 0.9458 - recall: 0.9789 - auc: 0.9633 - val_loss: 0.1365 - val_binary_accuracy: 0.9431 - val_precision: 0.9910 - val_recall: 0.8943 - val_auc: 0.9915\n",
      "Epoch 89/500\n",
      "1/1 - 0s - loss: 0.1944 - binary_accuracy: 0.9579 - precision: 0.9454 - recall: 0.9719 - auc: 0.9642 - val_loss: 0.1341 - val_binary_accuracy: 0.9431 - val_precision: 0.9910 - val_recall: 0.8943 - val_auc: 0.9919\n",
      "Epoch 90/500\n",
      "1/1 - 0s - loss: 0.1915 - binary_accuracy: 0.9579 - precision: 0.9454 - recall: 0.9719 - auc: 0.9650 - val_loss: 0.1319 - val_binary_accuracy: 0.9431 - val_precision: 0.9910 - val_recall: 0.8943 - val_auc: 0.9919\n",
      "Epoch 91/500\n",
      "1/1 - 0s - loss: 0.1886 - binary_accuracy: 0.9614 - precision: 0.9428 - recall: 0.9825 - auc: 0.9656 - val_loss: 0.1302 - val_binary_accuracy: 0.9431 - val_precision: 0.9910 - val_recall: 0.8943 - val_auc: 0.9920\n",
      "Epoch 92/500\n",
      "1/1 - 0s - loss: 0.1858 - binary_accuracy: 0.9614 - precision: 0.9428 - recall: 0.9825 - auc: 0.9661 - val_loss: 0.1289 - val_binary_accuracy: 0.9431 - val_precision: 0.9910 - val_recall: 0.8943 - val_auc: 0.9920\n",
      "Epoch 93/500\n",
      "1/1 - 0s - loss: 0.1830 - binary_accuracy: 0.9614 - precision: 0.9428 - recall: 0.9825 - auc: 0.9667 - val_loss: 0.1273 - val_binary_accuracy: 0.9431 - val_precision: 0.9910 - val_recall: 0.8943 - val_auc: 0.9922\n",
      "Epoch 94/500\n",
      "1/1 - 0s - loss: 0.1803 - binary_accuracy: 0.9614 - precision: 0.9428 - recall: 0.9825 - auc: 0.9673 - val_loss: 0.1253 - val_binary_accuracy: 0.9431 - val_precision: 0.9910 - val_recall: 0.8943 - val_auc: 0.9922\n",
      "Epoch 95/500\n",
      "1/1 - 0s - loss: 0.1776 - binary_accuracy: 0.9614 - precision: 0.9428 - recall: 0.9825 - auc: 0.9674 - val_loss: 0.1237 - val_binary_accuracy: 0.9431 - val_precision: 0.9910 - val_recall: 0.8943 - val_auc: 0.9923\n",
      "Epoch 96/500\n",
      "1/1 - 0s - loss: 0.1749 - binary_accuracy: 0.9614 - precision: 0.9428 - recall: 0.9825 - auc: 0.9675 - val_loss: 0.1225 - val_binary_accuracy: 0.9431 - val_precision: 0.9910 - val_recall: 0.8943 - val_auc: 0.9925\n",
      "Epoch 97/500\n",
      "1/1 - 0s - loss: 0.1723 - binary_accuracy: 0.9614 - precision: 0.9428 - recall: 0.9825 - auc: 0.9682 - val_loss: 0.1210 - val_binary_accuracy: 0.9431 - val_precision: 0.9910 - val_recall: 0.8943 - val_auc: 0.9926\n",
      "Epoch 98/500\n",
      "1/1 - 0s - loss: 0.1697 - binary_accuracy: 0.9614 - precision: 0.9428 - recall: 0.9825 - auc: 0.9692 - val_loss: 0.1186 - val_binary_accuracy: 0.9431 - val_precision: 0.9910 - val_recall: 0.8943 - val_auc: 0.9928\n",
      "Epoch 99/500\n",
      "1/1 - 0s - loss: 0.1671 - binary_accuracy: 0.9614 - precision: 0.9428 - recall: 0.9825 - auc: 0.9698 - val_loss: 0.1161 - val_binary_accuracy: 0.9431 - val_precision: 0.9910 - val_recall: 0.8943 - val_auc: 0.9928\n",
      "Epoch 100/500\n",
      "1/1 - 0s - loss: 0.1646 - binary_accuracy: 0.9614 - precision: 0.9428 - recall: 0.9825 - auc: 0.9701 - val_loss: 0.1143 - val_binary_accuracy: 0.9431 - val_precision: 0.9910 - val_recall: 0.8943 - val_auc: 0.9929\n",
      "Epoch 101/500\n",
      "1/1 - 0s - loss: 0.1620 - binary_accuracy: 0.9614 - precision: 0.9428 - recall: 0.9825 - auc: 0.9703 - val_loss: 0.1129 - val_binary_accuracy: 0.9431 - val_precision: 0.9910 - val_recall: 0.8943 - val_auc: 0.9931\n",
      "Epoch 102/500\n",
      "1/1 - 0s - loss: 0.1596 - binary_accuracy: 0.9614 - precision: 0.9428 - recall: 0.9825 - auc: 0.9709 - val_loss: 0.1107 - val_binary_accuracy: 0.9431 - val_precision: 0.9910 - val_recall: 0.8943 - val_auc: 0.9930\n",
      "Epoch 103/500\n",
      "1/1 - 0s - loss: 0.1572 - binary_accuracy: 0.9614 - precision: 0.9428 - recall: 0.9825 - auc: 0.9715 - val_loss: 0.1082 - val_binary_accuracy: 0.9756 - val_precision: 0.9916 - val_recall: 0.9593 - val_auc: 0.9930\n",
      "Epoch 104/500\n",
      "1/1 - 0s - loss: 0.1549 - binary_accuracy: 0.9649 - precision: 0.9431 - recall: 0.9895 - auc: 0.9722 - val_loss: 0.1063 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9930\n",
      "Epoch 105/500\n",
      "1/1 - 0s - loss: 0.1526 - binary_accuracy: 0.9649 - precision: 0.9431 - recall: 0.9895 - auc: 0.9725 - val_loss: 0.1056 - val_binary_accuracy: 0.9756 - val_precision: 0.9916 - val_recall: 0.9593 - val_auc: 0.9934\n",
      "Epoch 106/500\n",
      "1/1 - 0s - loss: 0.1503 - binary_accuracy: 0.9649 - precision: 0.9431 - recall: 0.9895 - auc: 0.9731 - val_loss: 0.1044 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9934\n",
      "Epoch 107/500\n",
      "1/1 - 0s - loss: 0.1481 - binary_accuracy: 0.9649 - precision: 0.9431 - recall: 0.9895 - auc: 0.9741 - val_loss: 0.1026 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9934\n",
      "Epoch 108/500\n",
      "1/1 - 0s - loss: 0.1459 - binary_accuracy: 0.9684 - precision: 0.9435 - recall: 0.9965 - auc: 0.9746 - val_loss: 0.1008 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9935\n",
      "Epoch 109/500\n",
      "1/1 - 0s - loss: 0.1438 - binary_accuracy: 0.9684 - precision: 0.9435 - recall: 0.9965 - auc: 0.9752 - val_loss: 0.1000 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9935\n",
      "Epoch 110/500\n",
      "1/1 - 0s - loss: 0.1416 - binary_accuracy: 0.9684 - precision: 0.9435 - recall: 0.9965 - auc: 0.9758 - val_loss: 0.0993 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/500\n",
      "1/1 - 0s - loss: 0.1395 - binary_accuracy: 0.9702 - precision: 0.9467 - recall: 0.9965 - auc: 0.9764 - val_loss: 0.0979 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9936\n",
      "Epoch 112/500\n",
      "1/1 - 0s - loss: 0.1374 - binary_accuracy: 0.9702 - precision: 0.9467 - recall: 0.9965 - auc: 0.9771 - val_loss: 0.0960 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9936\n",
      "Epoch 113/500\n",
      "1/1 - 0s - loss: 0.1353 - binary_accuracy: 0.9702 - precision: 0.9467 - recall: 0.9965 - auc: 0.9777 - val_loss: 0.0943 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9939\n",
      "Epoch 114/500\n",
      "1/1 - 0s - loss: 0.1332 - binary_accuracy: 0.9702 - precision: 0.9467 - recall: 0.9965 - auc: 0.9784 - val_loss: 0.0927 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9941\n",
      "Epoch 115/500\n",
      "1/1 - 0s - loss: 0.1311 - binary_accuracy: 0.9702 - precision: 0.9467 - recall: 0.9965 - auc: 0.9790 - val_loss: 0.0907 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9941\n",
      "Epoch 116/500\n",
      "1/1 - 0s - loss: 0.1289 - binary_accuracy: 0.9702 - precision: 0.9467 - recall: 0.9965 - auc: 0.9796 - val_loss: 0.0888 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9941\n",
      "Epoch 117/500\n",
      "1/1 - 0s - loss: 0.1267 - binary_accuracy: 0.9702 - precision: 0.9467 - recall: 0.9965 - auc: 0.9803 - val_loss: 0.0876 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9941\n",
      "Epoch 118/500\n",
      "1/1 - 0s - loss: 0.1246 - binary_accuracy: 0.9702 - precision: 0.9467 - recall: 0.9965 - auc: 0.9807 - val_loss: 0.0862 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9942\n",
      "Epoch 119/500\n",
      "1/1 - 0s - loss: 0.1224 - binary_accuracy: 0.9719 - precision: 0.9498 - recall: 0.9965 - auc: 0.9815 - val_loss: 0.0843 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9942\n",
      "Epoch 120/500\n",
      "1/1 - 0s - loss: 0.1204 - binary_accuracy: 0.9719 - precision: 0.9498 - recall: 0.9965 - auc: 0.9820 - val_loss: 0.0829 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9945\n",
      "Epoch 121/500\n",
      "1/1 - 0s - loss: 0.1184 - binary_accuracy: 0.9719 - precision: 0.9498 - recall: 0.9965 - auc: 0.9827 - val_loss: 0.0818 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9945\n",
      "Epoch 122/500\n",
      "1/1 - 0s - loss: 0.1164 - binary_accuracy: 0.9719 - precision: 0.9498 - recall: 0.9965 - auc: 0.9836 - val_loss: 0.0804 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9946\n",
      "Epoch 123/500\n",
      "1/1 - 0s - loss: 0.1143 - binary_accuracy: 0.9719 - precision: 0.9498 - recall: 0.9965 - auc: 0.9844 - val_loss: 0.0788 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9946\n",
      "Epoch 124/500\n",
      "1/1 - 0s - loss: 0.1123 - binary_accuracy: 0.9719 - precision: 0.9498 - recall: 0.9965 - auc: 0.9853 - val_loss: 0.0775 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9947\n",
      "Epoch 125/500\n",
      "1/1 - 0s - loss: 0.1103 - binary_accuracy: 0.9719 - precision: 0.9498 - recall: 0.9965 - auc: 0.9857 - val_loss: 0.0762 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9951\n",
      "Epoch 126/500\n",
      "1/1 - 0s - loss: 0.1082 - binary_accuracy: 0.9719 - precision: 0.9498 - recall: 0.9965 - auc: 0.9864 - val_loss: 0.0748 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9951\n",
      "Epoch 127/500\n",
      "1/1 - 0s - loss: 0.1061 - binary_accuracy: 0.9719 - precision: 0.9498 - recall: 0.9965 - auc: 0.9870 - val_loss: 0.0738 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9951\n",
      "Epoch 128/500\n",
      "1/1 - 0s - loss: 0.1041 - binary_accuracy: 0.9719 - precision: 0.9498 - recall: 0.9965 - auc: 0.9877 - val_loss: 0.0728 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9953\n",
      "Epoch 129/500\n",
      "1/1 - 0s - loss: 0.1020 - binary_accuracy: 0.9719 - precision: 0.9498 - recall: 0.9965 - auc: 0.9881 - val_loss: 0.0711 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9956\n",
      "Epoch 130/500\n",
      "1/1 - 0s - loss: 0.0999 - binary_accuracy: 0.9719 - precision: 0.9498 - recall: 0.9965 - auc: 0.9887 - val_loss: 0.0698 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9956\n",
      "Epoch 131/500\n",
      "1/1 - 0s - loss: 0.0978 - binary_accuracy: 0.9719 - precision: 0.9498 - recall: 0.9965 - auc: 0.9901 - val_loss: 0.0690 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9956\n",
      "Epoch 132/500\n",
      "1/1 - 0s - loss: 0.0957 - binary_accuracy: 0.9719 - precision: 0.9498 - recall: 0.9965 - auc: 0.9913 - val_loss: 0.0678 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9956\n",
      "Epoch 133/500\n",
      "1/1 - 0s - loss: 0.0935 - binary_accuracy: 0.9719 - precision: 0.9498 - recall: 0.9965 - auc: 0.9929 - val_loss: 0.0665 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9956\n",
      "Epoch 134/500\n",
      "1/1 - 0s - loss: 0.0915 - binary_accuracy: 0.9719 - precision: 0.9498 - recall: 0.9965 - auc: 0.9939 - val_loss: 0.0655 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9960\n",
      "Epoch 135/500\n",
      "1/1 - 0s - loss: 0.0894 - binary_accuracy: 0.9719 - precision: 0.9498 - recall: 0.9965 - auc: 0.9946 - val_loss: 0.0640 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9960\n",
      "Epoch 136/500\n",
      "1/1 - 0s - loss: 0.0873 - binary_accuracy: 0.9737 - precision: 0.9530 - recall: 0.9965 - auc: 0.9949 - val_loss: 0.0622 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9962\n",
      "Epoch 137/500\n",
      "1/1 - 0s - loss: 0.0852 - binary_accuracy: 0.9737 - precision: 0.9530 - recall: 0.9965 - auc: 0.9951 - val_loss: 0.0608 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9965\n",
      "Epoch 138/500\n",
      "1/1 - 0s - loss: 0.0831 - binary_accuracy: 0.9737 - precision: 0.9530 - recall: 0.9965 - auc: 0.9954 - val_loss: 0.0594 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9967\n",
      "Epoch 139/500\n",
      "1/1 - 0s - loss: 0.0810 - binary_accuracy: 0.9737 - precision: 0.9530 - recall: 0.9965 - auc: 0.9958 - val_loss: 0.0580 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9970\n",
      "Epoch 140/500\n",
      "1/1 - 0s - loss: 0.0789 - binary_accuracy: 0.9754 - precision: 0.9532 - recall: 1.0000 - auc: 0.9959 - val_loss: 0.0566 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9970\n",
      "Epoch 141/500\n",
      "1/1 - 0s - loss: 0.0769 - binary_accuracy: 0.9772 - precision: 0.9564 - recall: 1.0000 - auc: 0.9960 - val_loss: 0.0551 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9972\n",
      "Epoch 142/500\n",
      "1/1 - 0s - loss: 0.0748 - binary_accuracy: 0.9789 - precision: 0.9596 - recall: 1.0000 - auc: 0.9961 - val_loss: 0.0532 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9975\n",
      "Epoch 143/500\n",
      "1/1 - 0s - loss: 0.0727 - binary_accuracy: 0.9807 - precision: 0.9628 - recall: 1.0000 - auc: 0.9963 - val_loss: 0.0523 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9979\n",
      "Epoch 144/500\n",
      "1/1 - 0s - loss: 0.0706 - binary_accuracy: 0.9842 - precision: 0.9694 - recall: 1.0000 - auc: 0.9965 - val_loss: 0.0512 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9980\n",
      "Epoch 145/500\n",
      "1/1 - 0s - loss: 0.0687 - binary_accuracy: 0.9895 - precision: 0.9794 - recall: 1.0000 - auc: 0.9967 - val_loss: 0.0497 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9982\n",
      "Epoch 146/500\n",
      "1/1 - 0s - loss: 0.0668 - binary_accuracy: 0.9895 - precision: 0.9794 - recall: 1.0000 - auc: 0.9967 - val_loss: 0.0490 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9984\n",
      "Epoch 147/500\n",
      "1/1 - 0s - loss: 0.0650 - binary_accuracy: 0.9895 - precision: 0.9794 - recall: 1.0000 - auc: 0.9970 - val_loss: 0.0474 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/500\n",
      "1/1 - 0s - loss: 0.0632 - binary_accuracy: 0.9895 - precision: 0.9794 - recall: 1.0000 - auc: 0.9971 - val_loss: 0.0466 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9986\n",
      "Epoch 149/500\n",
      "1/1 - 0s - loss: 0.0615 - binary_accuracy: 0.9895 - precision: 0.9794 - recall: 1.0000 - auc: 0.9972 - val_loss: 0.0460 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9987\n",
      "Epoch 150/500\n",
      "1/1 - 0s - loss: 0.0598 - binary_accuracy: 0.9895 - precision: 0.9794 - recall: 1.0000 - auc: 0.9973 - val_loss: 0.0450 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9988\n",
      "Epoch 151/500\n",
      "1/1 - 0s - loss: 0.0581 - binary_accuracy: 0.9912 - precision: 0.9828 - recall: 1.0000 - auc: 0.9974 - val_loss: 0.0446 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9989\n",
      "Epoch 152/500\n",
      "1/1 - 0s - loss: 0.0565 - binary_accuracy: 0.9912 - precision: 0.9828 - recall: 1.0000 - auc: 0.9975 - val_loss: 0.0431 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9989\n",
      "Epoch 153/500\n",
      "1/1 - 0s - loss: 0.0550 - binary_accuracy: 0.9912 - precision: 0.9828 - recall: 1.0000 - auc: 0.9976 - val_loss: 0.0426 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9989\n",
      "Epoch 154/500\n",
      "1/1 - 0s - loss: 0.0535 - binary_accuracy: 0.9912 - precision: 0.9828 - recall: 1.0000 - auc: 0.9977 - val_loss: 0.0418 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9989\n",
      "Epoch 155/500\n",
      "1/1 - 0s - loss: 0.0520 - binary_accuracy: 0.9912 - precision: 0.9828 - recall: 1.0000 - auc: 0.9979 - val_loss: 0.0410 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9990\n",
      "Epoch 156/500\n",
      "1/1 - 0s - loss: 0.0506 - binary_accuracy: 0.9912 - precision: 0.9828 - recall: 1.0000 - auc: 0.9981 - val_loss: 0.0406 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9990\n",
      "Epoch 157/500\n",
      "1/1 - 0s - loss: 0.0493 - binary_accuracy: 0.9912 - precision: 0.9828 - recall: 1.0000 - auc: 0.9983 - val_loss: 0.0390 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9990\n",
      "Epoch 158/500\n",
      "1/1 - 0s - loss: 0.0479 - binary_accuracy: 0.9912 - precision: 0.9828 - recall: 1.0000 - auc: 0.9986 - val_loss: 0.0395 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9990\n",
      "Epoch 159/500\n",
      "1/1 - 0s - loss: 0.0467 - binary_accuracy: 0.9930 - precision: 0.9862 - recall: 1.0000 - auc: 0.9987 - val_loss: 0.0373 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9994\n",
      "Epoch 160/500\n",
      "1/1 - 0s - loss: 0.0455 - binary_accuracy: 0.9912 - precision: 0.9828 - recall: 1.0000 - auc: 0.9989 - val_loss: 0.0384 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9993\n",
      "Epoch 161/500\n",
      "1/1 - 0s - loss: 0.0444 - binary_accuracy: 0.9930 - precision: 0.9862 - recall: 1.0000 - auc: 0.9989 - val_loss: 0.0352 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9997\n",
      "Epoch 162/500\n",
      "1/1 - 0s - loss: 0.0434 - binary_accuracy: 0.9912 - precision: 0.9828 - recall: 1.0000 - auc: 0.9991 - val_loss: 0.0376 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9997\n",
      "Epoch 163/500\n",
      "1/1 - 0s - loss: 0.0424 - binary_accuracy: 0.9930 - precision: 0.9862 - recall: 1.0000 - auc: 0.9992 - val_loss: 0.0332 - val_binary_accuracy: 0.9959 - val_precision: 0.9919 - val_recall: 1.0000 - val_auc: 0.9998\n",
      "Epoch 164/500\n",
      "1/1 - 0s - loss: 0.0412 - binary_accuracy: 0.9912 - precision: 0.9828 - recall: 1.0000 - auc: 0.9994 - val_loss: 0.0362 - val_binary_accuracy: 0.9837 - val_precision: 0.9917 - val_recall: 0.9756 - val_auc: 0.9998\n",
      "Epoch 165/500\n",
      "1/1 - 0s - loss: 0.0400 - binary_accuracy: 0.9930 - precision: 0.9862 - recall: 1.0000 - auc: 0.9993 - val_loss: 0.0321 - val_binary_accuracy: 0.9878 - val_precision: 1.0000 - val_recall: 0.9756 - val_auc: 0.9999\n",
      "Epoch 166/500\n",
      "1/1 - 0s - loss: 0.0389 - binary_accuracy: 0.9912 - precision: 0.9828 - recall: 1.0000 - auc: 0.9995 - val_loss: 0.0332 - val_binary_accuracy: 0.9878 - val_precision: 1.0000 - val_recall: 0.9756 - val_auc: 0.9998\n",
      "Epoch 167/500\n",
      "1/1 - 0s - loss: 0.0378 - binary_accuracy: 0.9930 - precision: 0.9862 - recall: 1.0000 - auc: 0.9996 - val_loss: 0.0326 - val_binary_accuracy: 0.9878 - val_precision: 1.0000 - val_recall: 0.9756 - val_auc: 0.9998\n",
      "Epoch 168/500\n",
      "1/1 - 0s - loss: 0.0369 - binary_accuracy: 0.9930 - precision: 0.9862 - recall: 1.0000 - auc: 0.9997 - val_loss: 0.0310 - val_binary_accuracy: 0.9878 - val_precision: 1.0000 - val_recall: 0.9756 - val_auc: 1.0000\n",
      "Epoch 169/500\n",
      "1/1 - 0s - loss: 0.0361 - binary_accuracy: 0.9912 - precision: 0.9828 - recall: 1.0000 - auc: 0.9997 - val_loss: 0.0332 - val_binary_accuracy: 0.9878 - val_precision: 1.0000 - val_recall: 0.9756 - val_auc: 0.9998\n",
      "Epoch 170/500\n",
      "1/1 - 0s - loss: 0.0353 - binary_accuracy: 0.9930 - precision: 0.9862 - recall: 1.0000 - auc: 0.9997 - val_loss: 0.0298 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 171/500\n",
      "1/1 - 0s - loss: 0.0347 - binary_accuracy: 0.9912 - precision: 0.9828 - recall: 1.0000 - auc: 0.9998 - val_loss: 0.0321 - val_binary_accuracy: 0.9878 - val_precision: 1.0000 - val_recall: 0.9756 - val_auc: 0.9998\n",
      "Epoch 172/500\n",
      "1/1 - 0s - loss: 0.0339 - binary_accuracy: 0.9930 - precision: 0.9862 - recall: 1.0000 - auc: 0.9997 - val_loss: 0.0294 - val_binary_accuracy: 0.9878 - val_precision: 1.0000 - val_recall: 0.9756 - val_auc: 1.0000\n",
      "Epoch 173/500\n",
      "1/1 - 0s - loss: 0.0331 - binary_accuracy: 0.9930 - precision: 0.9862 - recall: 1.0000 - auc: 0.9998 - val_loss: 0.0299 - val_binary_accuracy: 0.9878 - val_precision: 1.0000 - val_recall: 0.9756 - val_auc: 1.0000\n",
      "Epoch 174/500\n",
      "1/1 - 0s - loss: 0.0325 - binary_accuracy: 0.9930 - precision: 0.9862 - recall: 1.0000 - auc: 0.9998 - val_loss: 0.0302 - val_binary_accuracy: 0.9878 - val_precision: 1.0000 - val_recall: 0.9756 - val_auc: 1.0000\n",
      "Epoch 175/500\n",
      "1/1 - 0s - loss: 0.0319 - binary_accuracy: 0.9930 - precision: 0.9862 - recall: 1.0000 - auc: 0.9998 - val_loss: 0.0282 - val_binary_accuracy: 0.9878 - val_precision: 1.0000 - val_recall: 0.9756 - val_auc: 1.0000\n",
      "Epoch 176/500\n",
      "1/1 - 0s - loss: 0.0313 - binary_accuracy: 0.9930 - precision: 0.9862 - recall: 1.0000 - auc: 0.9998 - val_loss: 0.0302 - val_binary_accuracy: 0.9878 - val_precision: 1.0000 - val_recall: 0.9756 - val_auc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x211dd42e288>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_model(None, 0.6)\n",
    "\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", min_delta=0.001, patience=15, mode=\"max\")\n",
    "model.fit(train_ds, epochs=500, verbose=2,validation_data=val_ds, callbacks=[earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(model.history, \"Final Model\", 0, 'val_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0347 - binary_accuracy: 0.9952 - precision: 0.9906 - recall: 1.0000 - auc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAG_response</th>\n",
       "      <th>Prob(response &lt; 0)</th>\n",
       "      <th>Predicted correctly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>True</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>True</td>\n",
       "      <td>0.997301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>False</td>\n",
       "      <td>0.007282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LAG_response  Prob(response < 0)  Predicted correctly\n",
       "503         True            1.000000                    1\n",
       "321         True            0.999967                    1\n",
       "503         True            1.000000                    1\n",
       "284         True            0.997301                    1\n",
       "415         True            1.000000                    1\n",
       "..           ...                 ...                  ...\n",
       "163        False            0.000000                    1\n",
       "20         False            0.000000                    1\n",
       "118        False            0.000000                    1\n",
       "601        False            0.000000                    1\n",
       "604        False            0.007282                    1\n",
       "\n",
       "[210 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)\n",
    "\n",
    "pred_results = model.predict(test_ds)\n",
    "\n",
    "#for i in range(len(predicted)):\n",
    "    #print(\"X=%s, Y=%s, Predicted=%s\" % (dict(test[headers].iloc[i]), test['LAG_response'].array[i], pred_results[i]))\n",
    "    #print(\"Y=%s, Predicted=%s\" % (test['LAG_response'].array[i], pred_results[i]))\n",
    "    \n",
    "predicted = test.copy()[headers]\n",
    "predicted[\"LAG_response\"] = test[\"LAG_response\"]\n",
    "predicted[\"Prob(response < 0)\"] = pred_results\n",
    "predicted_correctly = []\n",
    "for i in range(0, len(predicted[\"Prob(response < 0)\"])):\n",
    "    if (predicted[\"Prob(response < 0)\"].array[i] > 0.5 and predicted[\"LAG_response\"].array[i] == True) \\\n",
    "        or (predicted[\"Prob(response < 0)\"].array[i] < 0.5 and predicted[\"LAG_response\"].array[i] == False):\n",
    "        predicted_correctly.append(1)\n",
    "    else:\n",
    "        predicted_correctly.append(0)\n",
    "predicted[\"Predicted correctly\"] = predicted_correctly\n",
    "predicted[\"date\"] = dates\n",
    "predicted.to_csv(\"results.csv\")\n",
    "predicted[[\"LAG_response\", \"Prob(response < 0)\", \"Predicted correctly\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0304 - binary_accuracy: 0.9905 - precision: 0.9779 - recall: 0.9910 - auc: 0.9997\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAG_response</th>\n",
       "      <th>Prob(response &lt; 0)</th>\n",
       "      <th>Predicted correctly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>1.490116e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>9.986094e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>9.999768e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>False</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>False</td>\n",
       "      <td>7.748604e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>False</td>\n",
       "      <td>6.753206e-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>True</td>\n",
       "      <td>9.968623e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>True</td>\n",
       "      <td>9.999983e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>736 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LAG_response  Prob(response < 0)  Predicted correctly\n",
       "1           True        9.999998e-01                    1\n",
       "2          False        1.490116e-07                    1\n",
       "3           True        9.986094e-01                    1\n",
       "4          False        0.000000e+00                    1\n",
       "5           True        9.999768e-01                    1\n",
       "..           ...                 ...                  ...\n",
       "732        False        0.000000e+00                    1\n",
       "733        False        7.748604e-07                    1\n",
       "734        False        6.753206e-05                    1\n",
       "735         True        9.968623e-01                    1\n",
       "736         True        9.999983e-01                    1\n",
       "\n",
       "[736 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting over full history, i.e. including in-sample\n",
    "model.evaluate(total_ds)\n",
    "pred_results_full = model.predict(total_ds)\n",
    "\n",
    "predicted_full = total_df.copy()[headers]\n",
    "predicted_full[\"LAG_response\"] = total_df[\"LAG_response\"]\n",
    "predicted_full[\"Prob(response < 0)\"] = pred_results_full\n",
    "predicted_correctly = []\n",
    "for i in range(0, len(predicted_full[\"Prob(response < 0)\"])):\n",
    "    if (predicted_full[\"Prob(response < 0)\"].array[i] > 0.5 and predicted_full[\"LAG_response\"].array[i] == True) \\\n",
    "        or (predicted_full[\"Prob(response < 0)\"].array[i] < 0.5 and predicted_full[\"LAG_response\"].array[i] == False):\n",
    "        predicted_correctly.append(1)\n",
    "    else:\n",
    "        predicted_correctly.append(0)\n",
    "predicted_full[\"Predicted correctly\"] = predicted_correctly\n",
    "predicted_full[\"Date\"] = dates\n",
    "predicted_full.to_csv(\"results_full.csv\")\n",
    "predicted_full[[\"LAG_response\", \"Prob(response < 0)\", \"Predicted correctly\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_features (DenseFeature multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  192       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  6500      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  101       \n",
      "=================================================================\n",
      "Total params: 26,993\n",
      "Trainable params: 26,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
